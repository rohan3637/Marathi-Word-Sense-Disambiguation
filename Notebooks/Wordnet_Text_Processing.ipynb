{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_T3TbX7aJ7AW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UDSYM5KAJ7Ad"
   },
   "outputs": [],
   "source": [
    "DATA_TEXT_PATH = \"/content/drive/MyDrive/MARATHI_WSD_Data/Word_Net/data_txt.TXT\"\n",
    "IDX_NOUN_PATH = \"/content/drive/MyDrive/MARATHI_WSD_Data/Word_Net/idxnoun_txt.TXT\"\n",
    "IDX_PATH = \"/content/drive/MyDrive/MARATHI_WSD_Data/Word_Net/index_txt.TXT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aKsx0egNJ7Af"
   },
   "outputs": [],
   "source": [
    "opened_file = open(IDX_NOUN_PATH, \"r\", encoding=\"utf-8-sig\")\n",
    "idx_noun_content = opened_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Pd1ujjfiJ7Af"
   },
   "outputs": [],
   "source": [
    "noun_content = idx_noun_content.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4i9R-UPrJ7Af"
   },
   "outputs": [],
   "source": [
    "nouns = []\n",
    "for noun in noun_content:\n",
    "    text = noun.split(\" \")\n",
    "    try:\n",
    "        skip1 = int(text[2])\n",
    "        skip2 = skip1+1\n",
    "        nouns.append((text[0], text[2+skip2+1:]))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-U3KOw0PJ7Ag",
    "outputId": "d72a2497-3c26-42d6-a418-cc225fc73992"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('-तरंग', ['00005942']),\n",
       " ('-धारा', ['00027382']),\n",
       " ('-सारखा', ['00026718']),\n",
       " ('1000000', ['00031077']),\n",
       " ('10000000', ['00015838'])]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_Q22aytGJ7Aj"
   },
   "outputs": [],
   "source": [
    "opened_file = open(DATA_TEXT_PATH, \"r\", encoding=\"utf-8-sig\")\n",
    "data_content = opened_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ma2V6VzTJ7Ak"
   },
   "outputs": [],
   "source": [
    "data_content = data_content.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1rb3aHovJ7Ak"
   },
   "outputs": [],
   "source": [
    "all_syns = []\n",
    "for syn in data_content:\n",
    "    try:\n",
    "        ids, sentence = syn.split(\" | \")\n",
    "        x = ids.split(\" \")\n",
    "        all_syns.append((x[0], x[3].split(\":\"), sentence))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ERylDcRSJ7Al",
    "outputId": "873a007c-0a71-45bb-8b4d-2433a2d95edb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('00000001', ['अजन्मा'], 'ज्यास जन्म नाही असा:\"ईश्वर अजन्मा आहे\"'),\n",
       " ('00000002',\n",
       "  ['अशुभ', 'अमंगळ'],\n",
       "  'शुभ नाही असा:\"या योगामूळे कुंडलीतील इतर अशुभ योगांचा नाश होतो.\"'),\n",
       " ('00000003',\n",
       "  ['अप्रविष्ट'],\n",
       "  'ज्याने प्रवेश केला नाही असा:\"अप्रविष्ट व्यक्तींना ताबडतोब आत प्रवेश करू द्या.\"'),\n",
       " ('00000004',\n",
       "  ['पुण्यभूमी', 'पवित्रभूमी', 'पुण्यस्थान', 'पवित्रस्थान', 'पावनस्थान'],\n",
       "  'पवित्र मानले गेलेले स्थान:\"हिंदूंसाठी काशी ही पुण्यभूमी आहे.\"'),\n",
       " ('00000005',\n",
       "  ['शिवालय', 'शिवमंदिर'],\n",
       "  'जिथे शंकराच्या पिंडीची स्थापना केली असून त्याची पूजा होते ती जागा:\"ती दर सोमवारी शिवालयात जाते.\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_syns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8B5h3BhyLUbm",
    "outputId": "3d270727-e1c6-465c-ce11-80fb65840f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('00010818', ['राजस्थान'], 'भारतातील पश्चिमेला असलेला प्रदेश:\"राजस्थानाचा बहूतांश भाग वाळवंटी आहे.\"')\n"
     ]
    }
   ],
   "source": [
    "for i in all_syns:\r\n",
    "    if i[0] == \"00010818\":\r\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZjvcPFpNdv-",
    "outputId": "801743d0-bea1-4b6b-c55d-6f44fe139133"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28530"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanings = {}\r\n",
    "for syn in all_syns:\r\n",
    "    meanings[syn[0]] = syn[2]\r\n",
    "len(meanings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "id": "RlEmQ6QPNgGT",
    "outputId": "b13e6846-36f5-4c88-a154-4c79b74a17d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'भारतातील पश्चिमेला असलेला प्रदेश:\"राजस्थानाचा बहूतांश भाग वाळवंटी आहे.\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanings[\"00010818\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0GWYWdulMC0V"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7sOcFS8HNgI6"
   },
   "outputs": [],
   "source": [
    "pickle.dump(meanings, open(\"meanings.pkl\", \"wb+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Q7IBGlw8NgLV"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "WgjyLsBdNgOa"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Tiri54ONJ7Al"
   },
   "outputs": [],
   "source": [
    "# # Stemmers Loader\n",
    "# #Stemmers.txt file contains bigger words at stat so as to remove them first\n",
    "# stemmers = []\n",
    "\n",
    "# f = open('marathi_stemmers.txt',encoding='utf8',mode='r')\n",
    "# stemmers = f.readlines()\n",
    "\n",
    "# stemmers = [i[:-1] for i in stemmers]\n",
    "\n",
    "# def stemmer(word):\n",
    "#     import re\n",
    "#     for i in stemmers:\n",
    "#         if (i in word) & (len(word) > (len(i)+1)):\n",
    "#             return re.sub(i,\"\",word)\n",
    "#         else:\n",
    "#             pass\n",
    "#     return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-YpkLBfkJ7Am"
   },
   "outputs": [],
   "source": [
    "# def levenshteinDistance(s1, s2):\n",
    "#     if len(s1) > len(s2):\n",
    "#         s1, s2 = s2, s1\n",
    "\n",
    "#     distances = range(len(s1) + 1)\n",
    "#     for i2, c2 in enumerate(s2):\n",
    "#         distances_ = [i2+1]\n",
    "#         for i1, c1 in enumerate(s1):\n",
    "#             if c1 == c2:\n",
    "#                 distances_.append(distances[i1])\n",
    "#             else:\n",
    "#                 distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "#         distances = distances_\n",
    "#     return distances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "24cIJ7GdMFYl"
   },
   "outputs": [],
   "source": [
    "# all_syns = pickle.dump(all_syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QgEOuVaCMC25"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "xWUHDk9MJ7Am"
   },
   "outputs": [],
   "source": [
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "X0mPq7ciJ7Am"
   },
   "outputs": [],
   "source": [
    "nouns_data = []\n",
    "for noun in nouns:\n",
    "    for syn_id in noun[1]:\n",
    "        for syn in all_syns:\n",
    "            if syn_id == syn[0]:\n",
    "                sentence = syn[2].split(\" \")\n",
    "                flag = False\n",
    "                for synonym in syn[1]:\n",
    "                    match = difflib.get_close_matches(synonym, sentence)\n",
    "                    if len(match)!=0:\n",
    "                        flag = True\n",
    "                        sentence[sentence.index(match[0])] = noun[0]\n",
    "                        break\n",
    "                if flag:\n",
    "                    nouns_data.append((' '.join(sentence), noun[0], syn_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "o8MAQMx5QE0T"
   },
   "outputs": [],
   "source": [
    "for i in nouns_data:\r\n",
    "    if i[2] == \"00010818\":\r\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICkWMjF2J7Ao",
    "outputId": "d3af7762-a211-4ed7-c6d3-1f570a22a988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "अनामी ['अनाम', 'भाषा:\"अनामी']\n",
      "अनामी_भाषा []\n",
      "nआन्नाम []\n",
      "आन्नाम_भाषा []\n"
     ]
    }
   ],
   "source": [
    "for i in \"अनामी:अनामी_भाषा:nआन्नाम:आन्नाम_भाषा\".split(\":\"):\n",
    "    print(i, difflib.get_close_matches(i, 'अनाम ह्या प्रांताच्या लोकांची भाषा:\"अनामी ही मोन-ख्मेर कुळातली भाषा आहे.\"'.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZMO_iJaJ7As",
    "outputId": "01c30bf1-7b8d-457a-eeea-769b98ffe94d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31436"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nouns_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Jna4Hd0J7At",
    "outputId": "0bf4b38e-6daa-43bd-9af1-4da34a6ee9da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('इंग्रजी महिन्यातील बाराव्या दिवशी येणारी तारीख:\"पुढच्या महिन्याच्या 14 दसरा आहे.\"', '14', '00026902')\n",
      "('शंभर आणि पन्नास मिळून येणारी संख्या:\"पंच्याहत्तर आणि पंच्याहत्तर मिळूनदेखील 150 होतात.\"', '150', '00030156')\n",
      "('दहा अधिक सात मिळून होणारी संख्या:\"नऊ आणि आठची बेरीज 17 होते.\"', '17', '00013732')\n",
      "('दहा अधिक आठ मिळून होणारी संख्या:\"आपल्या पुराणांची संख्या 18 आहे\"', '18', '00002573')\n",
      "('वीस आणि नऊ मिळून होणारी संख्या:\"तीसामधून एक वजा केले असता 29 उत्तर येते.\"', '29', '00013759')\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,10):\n",
    "    print(nouns_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTj3byAdJ7Au",
    "outputId": "5b7187ec-479c-4f0c-eea8-4fe0466fc588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ऐंशी आणि तीन मिळून येणारी 83 तीनने भागता येत नाही.\"', '83', '00015768')\n",
      "('लांबीचे एक अँगस्ट्रॉम ह्या एककाचे नाम स्वीडिश शास्त्रज्ञाच्या नावावरून दिले आहे.\"', 'अँगस्ट्रॉम', '00027153')\n",
      "('मादागास्करची अँटाननरिव्हो हे मादागास्करचे सर्वात मोठे शहर आहे.\"', 'अँटाननरिव्हो', '00024174')\n",
      "('लक्ष्मणच्या दोन पुत्रांपैकी अंगद आणि चंद्रकेतु हे दोघे सख्खे भाऊ होते.\"', 'अंगद', '00019351')\n",
      "('शरीराची अंगबळ जोरावर तो कोणतेही काम करवून घेऊ शकतो\"', 'अंगबळ', '00009673')\n",
      "('एक अंगिरावृत वर्णन पुराणांमध्ये आढळते.\"', 'अंगिरावृत', '00029367')\n",
      "('बोटाला सुई टोचू नये म्हणून व सुईस मागून नेट मिळावा म्हणून तर्जनीत घालण्याचे एक धातूचे अंगुलीत्राण घालून शिवणकामाचा सराव कर\"', 'अंगुलीत्राण', '00002010')\n",
      "('बोटाला सुई टोचू नये म्हणून व सुईस मागून नेट मिळावा म्हणून तर्जनीत घालण्याचे एक धातूचे अंगुष्ठान घालून शिवणकामाचा सराव कर\"', 'अंगुष्ठान', '00002010')\n",
      "('बोटाला सुई टोचू नये म्हणून व सुईस मागून नेट मिळावा म्हणून तर्जनीत घालण्याचे एक धातूचे अंगुस्तन घालून शिवणकामाचा सराव कर\"', 'अंगुस्तन', '00002010')\n",
      "('बोटाला सुई टोचू नये म्हणून व सुईस मागून नेट मिळावा म्हणून तर्जनीत घालण्याचे एक धातूचे अंगुस्तान घालून शिवणकामाचा सराव कर\"', 'अंगुस्तान', '00002010')\n",
      "('हाताच्या अंगठ्यात घालावयाची एक प्रकारची अंगुस्तान लाल खडा आहे.\"', 'अंगुस्तान', '00014180')\n",
      "('बोटाला सुई टोचू नये म्हणून व सुईस मागून नेट मिळावा म्हणून तर्जनीत घालण्याचे एक धातूचे अंगुस्थान घालून शिवणकामाचा सराव कर\"', 'अंगुस्थान', '00002010')\n",
      "('विशिष्ट प्रकारची रसाळ फळे लागणारी अंगूर लावल्यापासून तीन वर्षांनी लागवडीला येते\"', 'अंगूर', '00001836')\n",
      "('वस्त्राचा,कापडाचा शेवटचा भाग.\"मूल आईचा अंचल धरून चालले होते\"', 'अंचल', '00002021')\n",
      "('केसरीची पत्नी व हनुमंताची आई.\"पुराणानुसार अंजना ही पूर्वजन्मी पुंजिकस्थली नावाची अप्सरा होती\"', 'अंजना', '00002028')\n",
      "('सात चिरंजीवांपैकी एक,वायू व अंजनी यांचा बलशाली अंजनिनंदन हे बलोपासनेचे प्रतीक आहे.\" ', 'अंजनिनंदन', '00002026')\n",
      "('केसरीची पत्नी व हनुमंताची आई.\"पुराणानुसार अंजनी ही पूर्वजन्मी पुंजिकस्थली नावाची अप्सरा होती\"', 'अंजनी', '00002028')\n",
      "('डोळ्याच्या पापणीला होणारी अंजिणी झाल्यास लसूण लावतात.\"', 'अंजिणी', '00000499')\n",
      "('पृथ्वीच्या दक्षिण ध्रुवाकडील अत्यंत थंड असलेला खंड जिथे तेरा हजार फूट जाडीचा बर्फ जमा अंटार्क्टिका हा ऑस्ट्रेलिया, युरोप या खंडांपाठोपाठ आकारमानाने तिसरा सर्वांत लहान खंड आहे.\"', 'अंटार्क्टिका', '00036428')\n"
     ]
    }
   ],
   "source": [
    "cnt = 1\n",
    "for i in nouns_data:\n",
    "    if \":\" not in i[0]:\n",
    "        cnt+=1\n",
    "        print(i)\n",
    "    if cnt == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "tslx1D-mJ7Av"
   },
   "outputs": [],
   "source": [
    "cleaned_noun_data = []\n",
    "for i in nouns_data:\n",
    "    try:\n",
    "        if len(i[0].split()) != 1:\n",
    "            if \"::\" in i[0]:\n",
    "                meaning, sentence = i[0].split(\"::\")\n",
    "            elif \":\" in i[0]:\n",
    "                meaning, sentence = i[0].split(\":\")\n",
    "            else:\n",
    "                meaning, sentence = i[0].split(\".\")\n",
    "            sentence = sentence[1:len(sentence)-1]\n",
    "    except:\n",
    "        if '\"' not in i[0]:\n",
    "            sentence = i[0]\n",
    "        else:\n",
    "            start = i[0].index('\"')\n",
    "            end = len(i[0])\n",
    "            sentence = i[0][start+1:end-1]\n",
    "    for sent in sentence.split(\"/\"):\n",
    "        cleaned_noun_data.append((sent, i[1], i[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybK7t3P1J7Aw",
    "outputId": "9660a051-c83b-4a29-f0df-781f199289e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32319"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_noun_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rc6z2cq2J7Aw",
    "outputId": "f8e7e193-d73c-4f4c-ec24-1dc645cf6060"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('तो संन्यासी अंगावरच्या भगव्या छाटी काहीही बरोबर बाळगत नाही',\n",
       "  'छाटी',\n",
       "  '00005252'),\n",
       " ('भाला त्याच्या छाताड घुसला ', 'छाताड', '00001960'),\n",
       " ('भाला त्याच्या छाती घुसला ', 'छाती', '00001960'),\n",
       " ('', 'छाती', '00001962'),\n",
       " ('मी साप हाती घेण्याचे छाती करीन पण दुसर्\\u200dयाला मारण्याचे नाही',\n",
       "  'छाती',\n",
       "  '00002958')]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_noun_data[10000:10005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "EtBr-q-qN7Z6"
   },
   "outputs": [],
   "source": [
    "def consine_similarity(l1, l2):\r\n",
    "    c = 0\r\n",
    "    for i in range(len(rvector)): \r\n",
    "        c+= l1[i]*l2[i] \r\n",
    "    cosine = c / float((sum(l1)*sum(l2))**0.5)\r\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "TiNTUFhcN7cg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "91e49e1d-55c9-4b6f-aa07-2a130cece950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['00023951', '00023958']]\n"
     ]
    }
   ],
   "source": [
    "given_sentence = \"मला कार्टून नेटवर्क चॅनेल खूपच आवडते!\"\r\n",
    "given_noun = \"कार्टून\"\r\n",
    "\r\n",
    "syn_ids = []\r\n",
    "for noun in nouns:\r\n",
    "    if noun[0] == given_noun:\r\n",
    "        syn_ids.append(noun[1])\r\n",
    "print(syn_ids)\r\n",
    "cosine_scores = []\r\n",
    "\r\n",
    "sents = []\r\n",
    "scores = []\r\n",
    "ids = []\r\n",
    "\r\n",
    "for i in syn_ids[0]:\r\n",
    "    for j in cleaned_noun_data:\r\n",
    "        if i == j[2]:\r\n",
    "            x = given_sentence.split(\" \")\r\n",
    "            y = j[0].split(\" \")\r\n",
    "            \r\n",
    "            X_set = {word for word in x}\r\n",
    "            Y_set = {word for word in y}\r\n",
    "\r\n",
    "            # print(X_set, Y_set)\r\n",
    "\r\n",
    "            rvector = X_set.union(Y_set)\r\n",
    "            l1, l2 = [], []\r\n",
    "            for w in rvector: \r\n",
    "                if w in X_set: \r\n",
    "                    l1.append(1) # create a vector \r\n",
    "                else: \r\n",
    "                    l1.append(0) \r\n",
    "                if w in Y_set: \r\n",
    "                    l2.append(1) \r\n",
    "                else: \r\n",
    "                    l2.append(0)\r\n",
    "            cosine_score = consine_similarity(l1,l2)\r\n",
    "            sents.append(j[0])\r\n",
    "            scores.append(cosine_score)\r\n",
    "            ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "axJL-C5QN7fZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "87098caa-599b-43ba-8c03-8414980d328f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आर. के लक्ष्मण ह्यांचे कार्टून खूप प्रभावी होते.', 'आर. के लक्ष्मण ह्यांचे व्यंगचित्र खूप प्रभावी होते.', 'आर. के लक्ष्मण ह्यांचे व्यंग्यचित्र खूप प्रभावी होते.', 'मुले टीवीवर कार्टून पाहत आहे.']\n",
      "[0.14433756729740646, 0.0, 0.0, 0.18257418583505536]\n",
      "['00023951', '00023951', '00023951', '00023958']\n"
     ]
    }
   ],
   "source": [
    "print(sents)\r\n",
    "print(scores)\r\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "bu9DBs8pN7kX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a501d993-02bb-4515-ad93-f073c3d0a39e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00023958\n"
     ]
    }
   ],
   "source": [
    "final_id = ids[np.argmax(scores)]\r\n",
    "print(final_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "L2RIEEprN749",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3f844db3-ebb9-4aaf-beb4-1e6692834aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meaning:  कार्टून वा अर्कचित्र वापरून साकारलेली चित्रफीत\n"
     ]
    }
   ],
   "source": [
    "for syn in all_syns:\r\n",
    "    if final_id == syn[0]:\r\n",
    "        print(\"Meaning: \",syn[2].split(\":\")[0])\r\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "6yY7WrMM4BMd"
   },
   "outputs": [],
   "source": [
    "meanings = {}\r\n",
    "for syn in all_syns:\r\n",
    "    meanings[syn[0]] = syn[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "ocoPdmxPGEnQ"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "WCZJor53oq8S"
   },
   "outputs": [],
   "source": [
    "nouns_set = {}\r\n",
    "for noun in nouns:\r\n",
    "    nouns_set[noun[0]] = noun[1]\r\n",
    "\r\n",
    "cleaned_noun_set = {}\r\n",
    "for noun in cleaned_noun_data:\r\n",
    "    cleaned_noun_set[noun[-1]] = noun[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "J7JdJF_NwIZL"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "CGfxjm06wIbh"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "fXxDt9IgRADQ"
   },
   "outputs": [],
   "source": [
    "pickle.dump(nouns_set, open(\"nouns.pkl\", \"wb+\"))\r\n",
    "pickle.dump(cleaned_noun_set, open(\"cleaned_noun_data.pkl\", \"wb+\"))\r\n",
    "pickle.dump(meanings, open(\"meanings.pkl\", \"wb+\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "colab": {
   "name": "Wordnet_Text_Processing.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
